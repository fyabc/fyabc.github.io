---
layout: post
title: DCCL
# description: 描述
permalink: /research-notes/DCCL
categories: [cat1, cat2, cat3]
---

## 链接

- 主页：<https://xxx>
- 正文：<https://xxx>
- 附件：<https://xxx>
- 代码：<https://xxx>
- 其他笔记：
  - <https://xxx>

## 信息

- Name: Device-Cloud Collaborative Learning for Recommendation
- Abbr: **DCCL**
- Author: XXX
- Affiliation: DAMO Alibaba
- Preprint/Received Time: 20XX.XX.XX
- Published Time: 20XX.XX.XX
- Meeting: XXX
- Citation: **XXX** (Check date)
- Dataset: XXX
- Main Method: XXX

## 文章解读

### Abstract

随着移动设备上存储和计算能力的快速发展，在设备上部署模型以节省繁重的通信延迟并捕获实时特征变得至关重要和流行。
虽然已经探索了很多工作来促进设备上的学习和推理，但其中大多数都专注于处理响应延迟或隐私保护。
对设备和云建模之间的协作进行建模并共同使双方受益的工作很少。
为了弥合这一差距，我们率先尝试研究设备-云协作学习 (DCCL) 框架。
具体来说，我们在设备端提出了一种新颖的元补丁学习方法，以在给定集中式云模型的情况下有效地实现“千人千模型”。
然后，针对数十亿个更新的个性化设备模型，我们提出了一种“模型覆盖模型”蒸馏算法，即 MoMoDistill，以更新集中式云模型。
我们对具有不同设置的一系列数据集进行了广泛的实验，证明了这种协作在云和设备上的有效性，尤其是其对长尾用户建模的优越性。

### Introduction

移动计算和物联网 (IoT) 的新兴应用正在推动计算走向分散 [38]。
特别是，移动设备不断发展的能力使得可以考虑从云到设备建模的智能服务，例如在线推荐。
最近，从隐私 [2, 22, 23]、效率 [4, 14]、应用程序 [8, 11, 42] 等不同角度的几项工作探索了这种普遍的计算优势。
因此，具有设备上引擎（例如 TFLite1 和 CoreML2）的移动推荐系统吸引了越来越多的关注。

先前在推荐系统领域的研究可以总结为两条线，在给定集中模型的情况下，设备上推理和设备上学习。
前者将预训练模型部署到设备上，并执行推理以节省繁重的通信延迟并捕获实时特征。
这主要解决了计算效率问题，产生了对设备友好模型推理的探索。
例如，Sun 等人。 [41] 提出了 CpRec 来缩小顺序推荐系统，它通过自适应分解和参数共享来压缩输入和输出矩阵的大小以及中间层的参数。在更广泛的领域，蔡等人。 [3] 引入了一种广义的网络剪枝方法，渐进式收缩，以减少跨维度的模型大小，以实现高效部署。
龚等人。 [11] 探索了跨云和设备的拆分部署，以降低设备上组件的推理成本。

后面的工作将时间设备上的训练片段聚合到一个集中式模型中，以克服隐私约束，即联合推荐系统 [44]。
来自集中式深度模型的本地副本的梯度首先在大量设备上执行，然后收集到服务器以通过联合平均 (FedAvg) 或其变体 [22, 23, 29] 更新模型参数。
例如，齐等人。 [33]将联邦学习和差分隐私应用于新闻推荐，在推荐性能和隐私保护之间取得了平衡。
林等人。 [27] 引入了 MetaMF 来考虑移动环境中的存储、能量和通信带宽，它将梯度计算分布在云和设备之间。
牛等人。 [30] 在梯度计算中遵循了类似的分割，但为局部子模型设计了一个可调的隐私。

与上述两条工作线不同，我们关注的是如何利用设备建模和云建模的优势共同使双方受益。
这个方向背后的直觉有两个方面：一方面，中心化的云模型通常会忽略甚至牺牲长尾样本、用户或物品的体验，以最大化全球收入。
而推荐样本中的长尾和非同分布（独立同分布）特征不可避免地会导致模型对少数群体的偏见[31]。
一种可能的解决方案是使用每个设备上的本地数据个性化云模型。
另一方面，单独在每个设备上的训练样本可能会受到局部优化的影响 [10]。
相比之下，集中式云模型使用来自所有设备的数据进行更新，并且能够避免这个问题。
这促使我们提出一个全面的设备-云协作学习 (DCCL) 框架。

我们总结了我们的贡献如下：
• 与仅考虑云建模、设备端推理或时间设备端训练片段聚合以处理隐私约束的现有工作相比，我们正式提出了一个设备-云协作学习框架 (DCCL) 以使双方受益。
• 我们提出了两种新方法 MetaPatch 和 MoMoDistill 来实例化 DCCL 中的每一方，它们考虑了设备上个性化的稀疏性挑战，并通过“模型对模型”MoMoDistill 蒸馏而不是传统的“模型”来增强集中式云模型-over-data”范式。
• 对一系列数据集的大量实验表明 DCCL 优于最先进的方法，特别是，我们提供了关于其对长尾用户的优势以及云和设备计算交互之间的内部循环的综合分析.

### Framework

1. 框架（3.1节）：推荐系统数据$$\{(x_n, y_n)\}_{n=1,\cdots,N}$$（以及每个设备各自的本地数据），云模型$$f$$和端模型$$f^(m)$$，云模型使用Patch固定部分参数，得到端模型
2. Model-over-Data: 受马太效应影响
   1. 从设备收集数据，用数据Fine-tune云模型
3. 端模型更新数据有限，容易陷入局部最优，这可以被中心化的云模型缓解
4. MetaPatch for On-device Personalization
   1. Previous work:可以使用Patch Learning得到性能不错的端模型
   2. 公式（1）：$$f'(x) = f(x) + h(f(x))$$，h为**补丁函数**
   3. 补丁h的空间仍然过大，使用元补丁减小参数空间（图（2））：使用**元补丁**$$\hat{\theta}$$和**全局基准参数**$$\Theta$$以生成补丁h的参数
   4. 使用本地数据Fine-tune元补丁（公式3）
5. Model-over-Model Distillation (MoMoDistill) to Enhance Cloud Modeling
   1. 除了使用普通的Model-over-Data的数据loss之外，还加入了云模型和端模型之间KL散度的loss（公式5）
   2. 将全局基准参数$$\Theta$$的训练和云模型f分开优化（它们扮演了不同角色，合在一起训练会陷入局部最优），使用公式（7）优化
6. **TODO**:写完这一篇

## 代码研究

正在完善中。
